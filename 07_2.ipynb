{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7H1n+xaKQMGKKilsbihFz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chocoding1/Machine_Learning_Deep_Learning/blob/main/07_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8Cqc7t-Cyg-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **심층 신경망**"
      ],
      "metadata": {
        "id": "iPTQshlYyiNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2개의 층"
      ],
      "metadata": {
        "id": "54bSKqkEyt8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB0dQvCEyd52",
        "outputId": "6564afe5-d593-40fa-d9fa-62168433ea02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 케라스 API를 사용하여 패션 MNIST 데이터셋 불러오기\n",
        "from tensorflow import keras\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 이미지의 픽셀값 0 ~ 1 사이로 변환\n",
        "train_scaled = train_input / 255.0\n",
        "# 2차원 배열 -> 1차원 배열\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "# 훈련 세트, 검증 세트 분리\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cBedkPg0y9cQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 인공 신경망 모델의 층을 2개 추가해보자.<br>\n",
        "\n",
        "입력층과 출력층 사이에 있는 모든 층을 **은닉층(hidden layer)**라고 한다.<br>\n",
        "\n",
        "은닉층에는 활성화 함수가 적용되는데, 출력층에서의 활성화 함수가 시그모이드 함수와 소프트맥스 함수로 한정되어 있는 것과 달리 은닉층의 활성화 함수는 비교적 자유롭다. 대표적으로 시그모이드 함수와 렐루(Relu) 함수 등을 사용한다.\n",
        "\n",
        "note) 은닉층에 활성화 함수를 적용하는 이유<br>\n",
        "선형적인 계산에 비선형성을 주기 위해서\n",
        "\n",
        "note) 회귀를 위한 신경망의 출력층에서는 어떤 활성화 함수를 사용하나?<br>\n",
        "위의 시그모이드와 소프트맥스는 분류를 위한 신경망의 출력층에서 사용한다.(클래스에 대한 확률을 출력하기 위해)<br>\n",
        "그러나 회귀의 출력은 임의의 어떤 숫자이므로 활성화 함수를 적용할 필요가 없다. 즉 출력층의 선형 방정식의 계산을 그대로 출력한다. 이렇게 하려면 Dense 층의 activation 매개변수에 아무런 값을 지정하지 않으면 된다."
      ],
      "metadata": {
        "id": "4BwSoSwQzqB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 시그모이드 활성화 함수를 사용한 은닉층과 소프트맥스 함수를 사용한 출력층을 만들어보자."
      ],
      "metadata": {
        "id": "hfcHlcVc1d8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')"
      ],
      "metadata": {
        "id": "tosUPcrhzglJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dense1 : 은닉층 / 100개의 뉴런을 가진 밀집층(은닉층의 뉴런 개수를 정하는 데에는 특별한 기준이 없다. 경험이 필요 / 그러나 한 가지, 적어도 출력층의 뉴런보다는 많게 만들어야 한다.)<br>\n",
        "dense2 : 출력층 / 10개의 클래스를 분류하므로 10개의 뉴런을 가진 밀집층"
      ],
      "metadata": {
        "id": "mCF3aqZo2AzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 심층 신경망 만들기\n",
        "\n",
        "Sequential 클래스의 객체를 만들 때 여러 개의 층을 추가하려면 각 층을 리스트로 만들어 전달해야 한다. 주의할 점은 출력층을 가장 마지막에 둬야 한다. 즉 해당 리스트는 가장 처음 등장하는 은닉층에서 마지막 출력층의 순서로 나열해야 한다."
      ],
      "metadata": {
        "id": "jrzZTk7r2gNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([dense1, dense2])"
      ],
      "metadata": {
        "id": "H8DeO7nt170V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "keras는 모델의 summary() 메서드를 호출하면 층에 대한 유용한 정보를 얻을 수 있다."
      ],
      "metadata": {
        "id": "LOqjgxR23Fyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMx688Gb2nV7",
        "outputId": "7aea35c5-bb74-4aa8-ca04-840a195bd6b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Shape의 첫 번째 자원은 샘플의 개수를 나타내는데, 샘플의 개수가 아직 정의되지 않았기 때문에 None이다. keras 모델의 fit() 메서드에 훈련 데이터를 주입하면 이 데이터를 한 번에 모두 사용하지 않고 미니배치 경사 하강법을 사용한다.<br>\n",
        "keras의 기본 미니배치 크기는 32이다. 이 값은 fit() 메서드의 batch_size 매개변수로 바꿀 수 있다. 따라서 샘플 개수를 고정하지 않고 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 설정한다.<br>\n",
        "\n",
        "두 번째 자원인 100은 은닉층의 뉴런 개수를 100으로 지정했기 때문에 나온 당연한 결과이다. 즉 샘플마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축되었다.\n",
        "\n",
        "마지막으로는 모델 파라미터 개수가 출력된다.<br>\n",
        "78500 = 785(픽셀 수) x 100(가중치 = 뉴런 수) + 100(절편 = 뉴런 수)\n",
        "\n",
        "summary() 메서드의 마지막에는 총 모델 파라미터 개수와 훈련되는 파라미터 개수가 동일하게 79,510으로 나온다. 은닉층과 출력층의 파라미터 개수를 합친 값이다. 그 아래 훈련되지 않는 파라미터(Non-trainable params)는 0으로 나오는데, 간혹 경사 하강법으로 훈련되지 않는 파라미터를 가진 층이 있다."
      ],
      "metadata": {
        "id": "YezYeJ5i4AfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 층을 추가하는 다른 방법\n",
        "\n",
        "1. Sequential 클래스 생성자 안에 바로 입력<br>\n",
        "dense1과 dense2처럼 밀집층 객체를 따로 저장하여 쓸 일이 없기 때문에 Sequential 클래스의 생성자 안에서 바로 Dense 클래스의 객체를 만드는 경우가 많다.<br>\n",
        "이렇게 작업하면 추가되는 층을 한눈에 쉽게 알아보는 장점이 있다."
      ],
      "metadata": {
        "id": "nOM5nuiz_gO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "    keras.layers.Dense(10, activation='softmax', name='output')\n",
        "], name='패션 MNIST 모델')"
      ],
      "metadata": {
        "id": "X_5hyovA3L-6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 모델의 이름과 층의 이름을 지정했는데, 모델의 이름과 달리 층의 이름은 반드시 영문이어야 한다."
      ],
      "metadata": {
        "id": "M4qOSBP7EicB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 층의 이름 확인\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0INiGG5tEiCr",
        "outputId": "92163a27-73e0-4763-8b34-340ffd1b80f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"패션 MNIST 모델\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 방법이 편리하지만 층이 아주 많아지면 Sequential 클래스 생성자가 매우 길어지고, 또 조건에 따라 층을 추가할 수도 없다."
      ],
      "metadata": {
        "id": "TvkMEQiFFLYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. add() 메서드 사용<br>\n",
        "Dense 클래스의 객체를 따로 변수에 담지 않고 바로 add() 메서드로 전달한다. 이 방법은 한눈에 추가되는 층을 볼 수 있고 프로그램 실행 시 동적으로 층을 선택하여 추가할 수 있다."
      ],
      "metadata": {
        "id": "_cAz3CPRGC7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "IRKqVE88EwJX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정보 확인\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfjQkKPlGVbT",
        "outputId": "4ede7232-c932-44ac-acf4-2f75599f519f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79510 (310.59 KB)\n",
            "Trainable params: 79510 (310.59 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO35nKusG2GY",
        "outputId": "a57e511a-574f-4715-d26d-c42a40440db8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5725 - accuracy: 0.8058\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4123 - accuracy: 0.8515\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3769 - accuracy: 0.8640\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3542 - accuracy: 0.8719\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3353 - accuracy: 0.8780\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d72d1a4c0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwvmlSmXHCeZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}